# ====================================================
# ========== Step 1 åŸºæœ¬åŒ¯å…¥èˆ‡åˆå§‹åŒ– =============
# ====================================================

# 1.1 æ¨™æº–åº«èˆ‡ç¬¬ä¸‰æ–¹å¥—ä»¶åŒ¯å…¥
import sys
import os
import time
import cv2
import json
import logging
from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, QTextEdit, QInputDialog, QMessageBox
from PyQt5.QtCore import QTimer, Qt, QPoint
from PyQt5.QtGui import QImage, QPixmap
from pydantic import BaseModel
import google.generativeai as genai
import threading

# 1.2 å°‡è·¯å¾‘é€€å›åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œè·¨è³‡æ–™å¤¾ import Insta_OpenCVï¼Œä¸¦åŠ å…¥ sys.path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from Insta_OpenCV.controller.insta_worker import InstaWorker                # åˆå§‹åŒ– Insta ç›¸æ©Ÿ
from Insta_OpenCV.utils.frame_receiver import FrameReceiver                 # RTMP å½±åƒæ¥æ”¶
from Insta_OpenCV.services.image_processing import ImageProcessingService   # å½±åƒè™•ç†æœå‹™
from Insta_OpenCV.services.system_monitor import get_global_system_monitor  # ç³»çµ±è³‡æºç›£æ§æœå‹™

# æ–°å¢: å°å…¥ OBS ä¸²æµæ•ç²æ¨¡çµ„
from obs_stream_capture import OBSStreamCapture                             # OBS è¦–é »æ•ç²
from obs_audio import OBSAudioCapture                                       # OBS éŸ³é »æ•ç²

# 1.3 è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ====================================================
# ========== Step 2 AI èˆ‡ Schema å®šç¾© =============
# ====================================================

# 2.1 å®šç¾©å°ç£èº«ä»½è­‰ Schema
class TaiwanIDCard(BaseModel):
    id_number: str
    name: str

# 2.2 Gemini client åˆå§‹åŒ–
def get_gemini_api_key():
    """ç²å– Gemini API Keyï¼Œå„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸ï¼Œå¦å‰‡å½ˆå‡ºè¼¸å…¥å°è©±æ¡†"""
    api_key = os.environ.get("GEMINI_API_KEY")
    
    if not api_key or api_key == "YOUR_API_KEY_HERE":
        # å½ˆå‡ºè¼¸å…¥å°è©±æ¡†
        api_key, ok = QInputDialog.getText(
            None, 
            'Gemini API Key', 
            'è«‹è¼¸å…¥ä½ çš„ Gemini API Key:\n(ä¹Ÿå¯è¨­å®šç’°å¢ƒè®Šæ•¸ GEMINI_API_KEY)',
            text=""
        )
        
        if not ok or not api_key.strip():
            QMessageBox.warning(None, "è­¦å‘Š", "æœªè¼¸å…¥ API Keyï¼ŒOCR åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ï¼")
            return "YOUR_API_KEY_HERE"
        
        # å¯é¸ï¼šå°‡ API Key è¨­å®šåˆ°ç’°å¢ƒè®Šæ•¸ï¼ˆåƒ…é™ç•¶å‰ç¨‹åºï¼‰
        os.environ["GEMINI_API_KEY"] = api_key.strip()
    
    return api_key.strip()

# å…ˆç”¨ç’°å¢ƒè®Šæ•¸æˆ–é è¨­å€¼åˆå§‹åŒ–ï¼Œä¹‹å¾Œåœ¨ main() ä¸­æœƒé‡æ–°è¨­å®š
genai.configure(api_key=os.environ.get("GEMINI_API_KEY", "YOUR_API_KEY_HERE"))
model = genai.GenerativeModel('gemini-1.5-pro')

# å‚™è¨»: 
# é€™å€‹å‡½å¼è¢«å‘¼å«å¾Œå°‡æœƒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿ
# 1. æ ¹æ“šæ˜¯å¦é¸æ“‡ ROIï¼Œæ±ºå®šä½¿ç”¨å…¨ç•«é¢æˆ– ROI å€åŸŸé€²è¡Œ OCR
# 2. ä½¿ç”¨ ImageProcessingService é€²è¡Œå“è³ªå¢å¼·
# 3. å‘¼å« Gemini OCR API é€²è¡Œè¾¨è­˜: 
# Gemini API Key è«‹è¨­å®šåœ¨ç³»çµ±ç’°å¢ƒè®Šæ•¸ä¸­ï¼Œæˆ–ç›´æ¥æ›¿æ›ä¸Šæ–¹ YOUR_API_KEY_HERE
# å¯æ–¼ cmd ä¸­åŸ·è¡Œ: setx GEMINI_API_KEY "ä½ çš„APIé‡‘é‘°"
# æˆ–åœ¨ Linux/MacOS çµ‚ç«¯æ©Ÿä¸­åŸ·è¡Œ: export GEMINI_API_KEY="ä½ çš„APIé‡‘é‘°"
# è©³ç´°è«‹åƒè€ƒå®˜æ–¹æ–‡ä»¶: https://developers.generativeai.google/products/gemini/get-started


# ====================================================
# ========== Step 3 ROI é è¦½è¦–çª—é¡åˆ¥ =============
# ====================================================

# å®šç¾© ROI é è¦½è¦–çª—ï¼Œå‰µå»ºä¸€å€‹æ–°çš„ QWidget é¡åˆ¥
class ROIPreviewWindow(QWidget):
    
    # 3.1 åˆå§‹åŒ–è¦–çª—èˆ‡å…ƒä»¶
    def __init__(self):
        super().__init__()                                              # å‘¼å«çˆ¶é¡åˆ¥åˆå§‹åŒ–
        self.setWindowTitle('ROI é«˜ç•«è³ªé è¦½')                            # è¨­å®šè¦–çª—æ¨™é¡Œ
        self.setFixedSize(600, 400)                                     # å›ºå®šè¦–çª—å¤§å°
        self.move(850, 100)                                             # ç§»å‹•è¦–çª—ä½ç½®

        self.preview_label = QLabel()                                   # é è¦½å½±åƒæ¨™ç±¤
        self.preview_label.setAlignment(Qt.AlignCenter)                 # ç½®ä¸­å°é½Š
        self.preview_label.setStyleSheet("border: 2px solid blue; background-color: #f0f0f0;")  # è¨­å®šæ¨£å¼
        self.preview_label.setText("é¸æ“‡ROIå€åŸŸå¾Œ\nå°‡é¡¯ç¤ºé«˜ç•«è³ªé è¦½")                             # é è¨­æ–‡å­—
        
        self.info_label = QLabel("å°šæœªé¸æ“‡å€åŸŸ")                         # è³‡è¨Šæ¨™ç±¤
        self.info_label.setAlignment(Qt.AlignCenter)                    # ç½®ä¸­å°é½Š
        self.info_label.setStyleSheet("color: #666; font-size: 12px;")  # è¨­å®šæ¨£å¼
        
        layout = QVBoxLayout()                                          # å‚ç›´ä½ˆå±€
        layout.addWidget(self.preview_label, 1)                         # é è¦½æ¨™ç±¤ä½”å¤§éƒ¨åˆ†ç©ºé–“
        layout.addWidget(self.info_label, 0)                            # è³‡è¨Šæ¨™ç±¤ä½”è¼ƒå°ç©ºé–“
        self.setLayout(layout)                                          # è¨­å®šä½ˆå±€

    # 3.2 æ›´æ–°é è¦½å½±åƒ
    def update_preview(self, roi_frame):
        
        # æ›´æ–°é è¦½å½±åƒ
        if roi_frame is not None and roi_frame.size > 0:
            img_service = ImageProcessingService()                              # åˆå§‹åŒ–å½±åƒè™•ç†æœå‹™
            pixmap = img_service.convert_frame_to_qt_format(roi_frame)          # ç›´æ¥è½‰æ›åŸå§‹ ROI ç•«é¢
            self.preview_label.setPixmap(pixmap)                                # è¨­å®šé è¦½å½±åƒ
            
            # é¡¯ç¤ºåŸå§‹ ROI è§£æåº¦è³‡è¨Š
            h, w = roi_frame.shape[:2]
            self.info_label.setText(f"åŸå§‹ ROI è§£æåº¦: {w}x{h}")
        else:
            self.clear_preview()
    
    # 3.3 æ¸…é™¤é è¦½
    def clear_preview(self):
        self.preview_label.clear()
        self.preview_label.setText("é¸æ“‡ROIå€åŸŸå¾Œ\nå°‡é¡¯ç¤ºé«˜ç•«è³ªé è¦½")
        self.info_label.setText("å°šæœªé¸æ“‡å€åŸŸ")


# ====================================================
# ========== Step 4 OCR é è¦½è¦–çª—é¡åˆ¥ =============
# ====================================================

# å®šç¾© OCR æ”åƒé ­ä¸»ä»‹é¢é¡åˆ¥
class OCRCameraWidget(QWidget):
    
    # 4.1 åˆå§‹åŒ–ä¸»ä»‹é¢
    def __init__(self):
        super().__init__()                                              # å‘¼å«çˆ¶é¡åˆ¥åˆå§‹åŒ–
        self.setWindowTitle('Gemini OCR èº«ä»½è­‰è¾¨è­˜')                     # è¨­å®šè¦–çª—æ¨™é¡Œ
        self.setFixedSize(800, 980)                                     # å›ºå®šè¦–çª—å¤§å° (å¢åŠ éŸ³é »é¡¯ç¤ºç©ºé–“)

        # 4.1.1 åˆå§‹åŒ–å½±åƒè™•ç†æœå‹™èˆ‡ç³»çµ±ç›£æ§
        self.image_service = ImageProcessingService()
        logger.info(f"[OCR] Image processing service initialized, GPU: {self.image_service.gpu_processor.is_gpu_available()}")
        self.system_monitor = get_global_system_monitor()
        self.system_monitor.start_monitoring()
        logger.info("[OCR] System monitoring started")
        self.current_frame = None
        self.original_frame = None  # ä¿å­˜åŸå§‹æœª resize çš„ç•«é¢
        
        # ä¿®æ”¹: ä½¿ç”¨ OBS ä¸²æµæ•ç²æ›¿ä»£åŸæœ‰çš„ receiver å’Œ worker
        self.obs_video_capture = None  # OBS è¦–é »æ•ç²å™¨
        self.obs_audio_capture = None  # OBS éŸ³é »æ•ç²å™¨
        self.insta_worker = None       # Insta Worker (ç”¨æ–¼å•Ÿå‹•ä¸²æµ)
        
        # ä¸²æµé…ç½®
        self.insta_ip = "192.168.1.188"
        self.rtmp_url = "rtmp://192.168.1.188:1935/live/preview"

        # å•Ÿå‹•ç³»çµ±è³‡æºç´€éŒ„åŸ·è¡Œç·’
        self._csv_thread = threading.Thread(target=export_system_metrics_to_csv, args=(self.system_monitor,), daemon=True)
        self._csv_thread.start()

        # 4.1.2 åˆå§‹åŒ– ROI é¸æ“‡ç›¸é—œè®Šæ•¸
        self.roi_start = None
        self.roi_end = None
        self.roi_selecting = False
        self.roi_selected = False
        self.display_scale = 1.0
        self.display_offset_x = 0
        self.display_offset_y = 0
        self.frame_count = 0

        # 4.1.3 åˆå§‹åŒ– UI å…ƒä»¶
        self._init_ui()                                                 # åˆå§‹åŒ– UI å…ƒä»¶
        self.roi_preview = ROIPreviewWindow()                           # åˆå§‹åŒ– ROI é è¦½è¦–çª—
        self.roi_preview.hide()                                         # é è¨­éš±è—
        self._start_frame_timer()                                       # å•Ÿå‹•å½±åƒæ›´æ–°å®šæ™‚å™¨
        self._init_camera_system()                                      # åˆå§‹åŒ–æ”åƒé ­ç³»çµ±
        
    # 4.2 åˆå§‹åŒ– UI å…ƒä»¶
    def _init_ui(self):
       
        # 4.2.1 å½±åƒé¡¯ç¤ºæ¨™ç±¤
        self.image_label = QLabel()                                     # å½±åƒé¡¯ç¤ºæ¨™ç±¤
        self.image_label.setAlignment(Qt.AlignCenter)                   # ç½®ä¸­å°é½Š
        self.image_label.setMinimumSize(780, 440)                       # è¨­å®šæœ€å°å°ºå¯¸
        self.image_label.setStyleSheet("border: 2px solid gray;")       # è¨­å®šæ¨£å¼
        self.image_label.setMouseTracking(True)                         # å•Ÿç”¨æ»‘é¼ è¿½è¹¤
        self.image_label.installEventFilter(self)                       # å®‰è£äº‹ä»¶éæ¿¾å™¨
        
        # 4.2.2 æ§åˆ¶æŒ‰éˆ•
        self.roi_btn = QPushButton('é¸æ“‡è¾¨è­˜å€åŸŸ (æ‹–æ‹½æ¡†é¸)')             # ROI é¸æ“‡æŒ‰éˆ•
        self.roi_btn.clicked.connect(self.toggle_roi_mode)              # é€£æ¥æŒ‰éˆ•äº‹ä»¶
        self.roi_btn.setMinimumHeight(40)                               # è¨­å®šæœ€å°é«˜åº¦
        self.clear_roi_btn = QPushButton('æ¸…é™¤é¸æ“‡å€åŸŸ')                 # æ¸…é™¤ ROI æŒ‰éˆ•
        self.clear_roi_btn.clicked.connect(self.clear_roi)              # é€£æ¥æŒ‰éˆ•äº‹ä»¶
        self.clear_roi_btn.setMinimumHeight(40)                         # è¨­å®šæœ€å°é«˜åº¦
        self.capture_btn = QPushButton('æ‹ç…§ä¸¦è¾¨è­˜')                     # æ‹ç…§ä¸¦è¾¨è­˜æŒ‰éˆ•
        self.capture_btn.clicked.connect(self.capture_and_ocr)          # é€£æ¥æŒ‰éˆ•äº‹ä»¶
        self.capture_btn.setMinimumHeight(40)                           # è¨­å®šæœ€å°é«˜åº¦

        # 4.2.3 çµæœé¡¯ç¤º
        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        self.result_text.setMinimumHeight(200)
        
        # 4.2.4 ç‹€æ…‹èˆ‡è³‡æºç›£æ§é¡¯ç¤º
        self.status_label = QLabel("ç³»çµ±ç‹€æ…‹: åˆå§‹åŒ–ä¸­...")
        self.status_label.setStyleSheet("color: #666; font-size: 10px; padding: 5px;")
        self.resource_label = QLabel("ç³»çµ±è³‡æº: ç›£æ§ä¸­...")
        self.resource_label.setStyleSheet("color: #333; font-size: 10px; padding: 5px; background-color: #f0f0f0;")
        self.resource_label.setWordWrap(True)
        
        # 4.2.5 éŸ³é »é¡¯ç¤ºå€åŸŸ
        self.audio_label = QLabel("éŸ³é »ç‹€æ…‹: åˆå§‹åŒ–ä¸­...")
        self.audio_label.setStyleSheet("color: #333; font-size: 10px; padding: 5px; background-color: #e8f4f8;")
        self.audio_label.setWordWrap(True)
        
        # éŸ³é‡æ¢é¡¯ç¤º
        self.volume_bar = QLabel()
        self.volume_bar.setFixedHeight(20)
        self.volume_bar.setStyleSheet("border: 1px solid #ccc; background-color: #f0f0f0;")
        self.volume_bar.setText("éŸ³é‡: --")
        self.volume_bar.setAlignment(Qt.AlignCenter)
        
        # 4.2.6 ä½ˆå±€
        button_layout = QHBoxLayout()                                   # æ°´å¹³ä½ˆå±€
        button_layout.addWidget(self.roi_btn)                           # åŠ å…¥ ROI æŒ‰éˆ•
        button_layout.addWidget(self.clear_roi_btn)                     # åŠ å…¥æ¸…é™¤ ROI æŒ‰éˆ•
        button_layout.addWidget(self.capture_btn)                       # åŠ å…¥æ‹ç…§è¾¨è­˜æŒ‰éˆ•
        
        # éŸ³é »é¡¯ç¤ºä½ˆå±€
        audio_layout = QHBoxLayout()
        audio_layout.addWidget(QLabel("ğŸ”Š éŸ³é‡:"))
        audio_layout.addWidget(self.volume_bar, 1)
        
        layout = QVBoxLayout()                                          # å‚ç›´ä½ˆå±€
        layout.addWidget(self.image_label, 1)                           # å½±åƒæ¨™ç±¤
        layout.addLayout(button_layout, 0)                              # æŒ‰éˆ•ä½ˆå±€
        layout.addWidget(self.result_text, 0)                           # çµæœé¡¯ç¤º
        layout.addWidget(self.status_label, 0)                          # ç‹€æ…‹é¡¯ç¤º
        layout.addWidget(self.resource_label, 0)                        # è³‡æºç›£æ§é¡¯ç¤º
        layout.addLayout(audio_layout, 0)                               # éŸ³é »é¡¯ç¤ºä½ˆå±€
        layout.addWidget(self.audio_label, 0)                           # éŸ³é »è©³ç´°è³‡è¨Š
        self.setLayout(layout)                                          # è¨­å®šä½ˆå±€
    
    
    # 4.3 åˆå§‹åŒ–æ”åƒé ­ç³»çµ± (ä¿®æ”¹ç‚ºä½¿ç”¨ OBS)
    def _init_camera_system(self):
        
        try:
            logger.info("[OCR] Initializing camera system with OBS...")
            
            # 4.3.1 åˆå§‹åŒ– InstaWorker (ç”¨æ–¼å•Ÿå‹• RTMP ä¸²æµ)
            self.insta_worker = InstaWorker(ip_address=self.insta_ip)
            ready_event = self.insta_worker.start_preview_all()
            
            # 4.3.2 ç­‰å¾… InstaWorker å°±ç·’
            logger.info("[OCR] Waiting for Insta worker to be ready...")
            ready_event.wait()
            logger.info("[OCR] Insta worker ready! Waiting for stream stabilization...")
            time.sleep(5)  # ç­‰å¾…ä¸²æµç©©å®š
            
            # 4.3.3 åˆå§‹åŒ– OBS è¦–é »æ•ç²å™¨ - è¨­ç½®é¡¯ç¤ºç¸®æ”¾
            logger.info("[OCR] Starting OBS video capture...")
            self.obs_video_capture = OBSStreamCapture(
                stream_url=self.rtmp_url,
                capture_audio=False,  # éŸ³é »å–®ç¨è™•ç†
                display_scale=0.33,   # ç›´æ¥åœ¨ OBS å±¤ç¸®æ”¾åˆ° 1/3
                max_display_width=1280,
                max_display_height=720
            )
            
            if not self.obs_video_capture.start():
                logger.error("[OCR] Failed to start OBS video capture")
                raise Exception("OBS video capture startup failed")
            
            logger.info("[OCR] OBS video capture started successfully")
            
            # 4.3.4 åˆå§‹åŒ– OBS éŸ³é »æ•ç²å™¨ (å¯é¸)
            try:
                self.obs_audio_capture = OBSAudioCapture(stream_url=self.rtmp_url)
                if self.obs_audio_capture.start_capture():
                    logger.info("[OCR] OBS audio capture started successfully")
                else:
                    logger.warning("[OCR] OBS audio capture failed to start")
            except Exception as e:
                logger.warning(f"[OCR] Audio capture initialization failed: {e}")
                self.obs_audio_capture = None
            
            # åˆå§‹åŒ–ç•¶å‰å¹€
            self.current_frame = None
            
            logger.info("[OCR] Camera system with OBS initialized successfully")
            self.status_label.setText("ç³»çµ±ç‹€æ…‹: OBS ä¸²æµå·²é€£æ¥ï¼ŒGPUåŠ é€Ÿå·²å•Ÿç”¨")
            
        except Exception as e:
            logger.error(f"[OCR] Failed to initialize camera system: {e}")
            self.status_label.setText(f"ç³»çµ±ç‹€æ…‹: æ”åƒé ­åˆå§‹åŒ–å¤±æ•— - {e}")
            
            # æ¸…ç†è³‡æº
            if self.obs_video_capture:
                self.obs_video_capture.stop()
                self.obs_video_capture = None
            if self.obs_audio_capture:
                self.obs_audio_capture.stop_capture()
                self.obs_audio_capture = None
            if self.insta_worker:
                self.insta_worker.stop_all()
                self.insta_worker = None
    
    # 4.4 FPS å®šæ™‚å™¨èˆ‡å½±åƒæ›´æ–°
    def _start_frame_timer(self):
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(33)  # 30 FPS (1000ms/30 â‰ˆ 33.33ms)
        
        # å•Ÿå‹•é¡å¤–çš„ä½å»¶é²å®šæ™‚å™¨ä¾†æ¸…ç†èˆŠå¹€
        self.cleanup_timer = QTimer()
        self.cleanup_timer.timeout.connect(self._cleanup_old_frames)
        self.cleanup_timer.start(16)  # æ¯16msæ¸…ç†ä¸€æ¬¡èˆŠå¹€
        
    def _cleanup_old_frames(self):
        """æ¸…ç†èˆŠå¹€ä»¥æ¸›å°‘å»¶é² (ä¿®æ”¹ç‚ºä½¿ç”¨ OBSï¼Œéé˜»å¡æ–¹å¼)"""
        if self.obs_video_capture:
            # ç²å–æœ€æ–°å¹€ï¼ŒOBS æ•ç²å™¨å…§éƒ¨å·²è™•ç†å¹€ç·©è¡
            # é€™è£¡åªæ˜¯æª¢æŸ¥æ˜¯å¦æœ‰æ–°å¹€ï¼Œä¸é€²è¡Œè€—æ™‚çš„è™•ç†
            latest_frame = self.obs_video_capture.get_latest_frame()
            if latest_frame is not None and self.original_frame is None:
                # åªåœ¨æ²’æœ‰åŸå§‹ç•«é¢æ™‚æ‰è¨­ç½®ï¼Œé¿å…é »ç¹æ›´æ–°
                self.original_frame = latest_frame
        
    # å‚™è¨»ï¼Œå½±åƒæ›´æ–°é‚è¼¯:
    # 1. å¾ FrameReceiver ç²å–æœ€æ–°å¹€
    # 2. ä½¿ç”¨ ImageProcessingService è™•ç†å½±åƒé¡¯ç¤º
    # 3. ç¹ªè£½ ROI è¦†è“‹å±¤
    # å‡å¦‚æ‹‰å–å½±åƒé€Ÿåº¦è·Ÿä¸ä¸Šæ›´æ–°é »ç‡ï¼Œæœƒè·³éå¹€ä»¥ä¿æŒ UI æµæš¢
    
    
    # 4.5 å½±åƒæ›´æ–°èˆ‡é¡¯ç¤º (ä½¿ç”¨ OBS é ç¸®æ”¾ç•«é¢)
    def update_frame(self):
        
        # 4.5.1 æª¢æŸ¥ OBS æ•ç²å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if self.obs_video_capture is None:
            return
            
        # 4.5.2 å¾ OBS æ•ç²å™¨ç²å–é ç¸®æ”¾çš„é¡¯ç¤ºç•«é¢
        display_frame = self.obs_video_capture.get_latest_frame()  # å·²ç¶“æ˜¯ç¸®æ”¾å¾Œçš„ç•«é¢
        original_frame = self.obs_video_capture.get_original_frame()  # åŸå§‹é«˜è§£æåº¦ç•«é¢
                
        if display_frame is None:
            return
        
        # 4.5.2.1 ä¿å­˜å…©ç¨®ç•«é¢
        if original_frame is not None:
            self.original_frame = original_frame.copy()
        
        self.current_frame = display_frame  # ä½¿ç”¨é ç¸®æ”¾çš„ç•«é¢é€²è¡Œé¡¯ç¤º
        self.frame_count += 1
        
        # 4.5.3 ä½¿ç”¨ ImageProcessingService è™•ç†å½±åƒé¡¯ç¤º
        if self.current_frame is not None:
            label_width = self.image_label.width()                          # å–å¾—æ¨™ç±¤å¯¬åº¦
            label_height = self.image_label.height()                        # å–å¾—æ¨™ç±¤é«˜åº¦
            
            display_frame, scale, offset_x, offset_y = self.image_service.prepare_frame_for_display(
                self.current_frame, label_width, label_height
            )                                                               # è™•ç†å½±åƒä»¥é©æ‡‰æ¨™ç±¤å°ºå¯¸
            
            if display_frame is None:
                return
            
            # 4.5.4 å„²å­˜é¡¯ç¤ºåƒæ•¸ä¾› ROI è¨ˆç®—ä½¿ç”¨
            self.display_scale = scale                                      # ç¸®æ”¾æ¯”ä¾‹
            self.display_offset_x = offset_x                                # X è»¸åç§»
            self.display_offset_y = offset_y                                # Y è»¸åç§»

            # 4.5.5 ç¹ªè£½ ROI è¦†è“‹å±¤
            if self.roi_selected and self.roi_start and self.roi_end:
                roi_coords = self._get_roi_display_coords()
                if roi_coords:
                    display_frame = self.image_service.draw_roi_overlay(
                        display_frame, roi_coords, color=(0, 255, 0), label="OCR Region"
                    )
            elif self.roi_selecting and self.roi_start and self.roi_end:
                roi_coords = self._get_roi_display_coords()
                if roi_coords:
                    display_frame = self.image_service.draw_roi_overlay(
                        display_frame, roi_coords, color=(255, 255, 0), thickness=2, label=""
                    )
            
            # 4.5.6 è½‰æ›ç‚º Qt æ ¼å¼ä¸¦é¡¯ç¤º
            pixmap = self.image_service.convert_frame_to_qt_format(display_frame)
            self.image_label.setPixmap(pixmap)
            
            # ä¿å­˜è™•ç†å¾Œçš„é¡¯ç¤ºç•«é¢
            self.display_frame = display_frame

        # 4.5.7 æ›´æ–° OBS å’Œç³»çµ±ç‹€æ…‹ï¼ˆæ¯200å¹€ä¸€æ¬¡ï¼Œé™ä½é »ç‡ï¼‰
        if self.frame_count % 200 == 0:
            try:
                # ç²å– OBS çµ±è¨ˆä¿¡æ¯
                obs_stats = self.obs_video_capture.get_stats()
                fps_info = f"FPS: {obs_stats.get('fps', 0):.1f}"
                
                # ç²å–éŸ³é »ä¿¡æ¯ä¸¦æ›´æ–°é¡¯ç¤º
                audio_info = ""
                if self.obs_audio_capture:
                    audio_level = self.obs_audio_capture.get_audio_level()
                    audio_info = f" | Audio: {audio_level:.2f}"
                    self._update_audio_display(audio_level)
                else:
                    self._update_audio_display(0.0)
                
                self.status_label.setText(f"ç³»çµ±ç‹€æ…‹: OBSä¸²æµ {fps_info}{audio_info} | GPUåŠ é€Ÿå·²å•Ÿç”¨")
                
                # ç³»çµ±è³‡æºä¿¡æ¯
                resource_summary = self.system_monitor.get_resource_summary()
                self.resource_label.setText(f"ç³»çµ±è³‡æº: {resource_summary}")
                
            except Exception as e:
                logger.warning(f"[OCR] Error updating status: {e}")
        
        # éŸ³é »é¡¯ç¤ºæ›´æ–° (æ¯30å¹€ä¸€æ¬¡ï¼Œæ›´é »ç¹ä»¥ç¢ºä¿éŸ³é »å¯è¦–åŒ–æµæš¢)
        elif self.frame_count % 30 == 0 and self.obs_audio_capture:
            try:
                audio_level = self.obs_audio_capture.get_audio_level()
                self._update_audio_display(audio_level)
            except Exception as e:
                logger.warning(f"[Audio] Error updating audio display: {e}")
    
    # 4.5.8 æ›´æ–°éŸ³é »é¡¯ç¤º
    def _update_audio_display(self, audio_level):
        """æ›´æ–°éŸ³é »é¡¯ç¤ºå€åŸŸ"""
        try:
            # éŸ³é‡æ¢å¯è¦–åŒ– (0-100%)
            volume_percent = min(100, max(0, audio_level * 100))
            bar_width = int(volume_percent * 2)  # æœ€å¤§200åƒç´ å¯¬åº¦
            
            # æ ¹æ“šéŸ³é‡å¤§å°è¨­ç½®é¡è‰²
            if volume_percent > 80:
                color = "#ff4444"  # ç´…è‰² - éå¤§
            elif volume_percent > 50:
                color = "#ffaa00"  # æ©™è‰² - é©ä¸­åå¤§
            elif volume_percent > 20:
                color = "#44ff44"  # ç¶ è‰² - é©ä¸­
            else:
                color = "#aaaaaa"  # ç°è‰² - éå°
            
            # æ›´æ–°éŸ³é‡æ¢æ¨£å¼
            self.volume_bar.setStyleSheet(f"""
                QLabel {{
                    border: 1px solid #ccc;
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                        stop:0 {color}, stop:{volume_percent/100:.2f} {color},
                        stop:{volume_percent/100:.2f} #f0f0f0, stop:1 #f0f0f0);
                    color: black;
                    font-weight: bold;
                }}
            """)
            self.volume_bar.setText(f"éŸ³é‡: {volume_percent:.1f}%")
            
            # æ›´æ–°éŸ³é »è©³ç´°è³‡è¨Š
            if self.obs_audio_capture:
                audio_info = self.obs_audio_capture.get_audio_info()
                self.audio_label.setText(
                    f"éŸ³é »è©³æƒ…: æ¡æ¨£ç‡: {audio_info.get('sample_rate', 'N/A')}Hz | "
                    f"è²é“: {audio_info.get('channels', 'N/A')} | "
                    f"ä½æ·±: {audio_info.get('bit_depth', 'N/A')}bit | "
                    f"éŸ³é‡: {volume_percent:.1f}%"
                )
            else:
                self.audio_label.setText("éŸ³é »è©³æƒ…: éŸ³é »æ•ç²æœªå•Ÿç”¨")
                
        except Exception as e:
            logger.warning(f"[Audio] Error updating audio display: {e}")
            self.audio_label.setText(f"éŸ³é »ç‹€æ…‹: æ›´æ–°éŒ¯èª¤ - {e}")
    
    
    # 4.6 ROI é¸æ“‡ç›¸é—œæ–¹æ³•
    def _get_roi_display_coords(self):
        
        if not (self.roi_start and self.roi_end):
            return None
        
        x1 = min(self.roi_start.x(), self.roi_end.x())                  # å·¦ä¸Šè§’ X
        y1 = min(self.roi_start.y(), self.roi_end.y())                  # å·¦ä¸Šè§’ Y
        x2 = max(self.roi_start.x(), self.roi_end.x())                  # å³ä¸‹è§’ X
        y2 = max(self.roi_start.y(), self.roi_end.y())                  # å³ä¸‹è§’ Y

        return (x1, y1, x2, y2)
    
    
    # 4.7 äº‹ä»¶éæ¿¾å™¨è™•ç†æ»‘é¼ äº‹ä»¶
    def eventFilter(self, obj, event):
        
        # 4.7.1 åƒ…è™•ç†å½±åƒæ¨™ç±¤ä¸Šçš„æ»‘é¼ äº‹ä»¶ï¼Œä¸”éœ€æœ‰å½±åƒèˆ‡ OBS æ•ç²å™¨
        if obj == self.image_label and self.current_frame is not None and self.obs_video_capture is not None:
            
            # 4.7.2 è™•ç†æ»‘é¼ å·¦éµæŒ‰ä¸‹äº‹ä»¶ï¼Œé–‹å§‹ ROI é¸æ“‡
            if event.type() == event.MouseButtonPress:      # è™•ç†æ»‘é¼ æŒ‰ä¸‹äº‹ä»¶
                if event.button() == Qt.LeftButton:
                    mouse_pos = self._convert_mouse_coords(event.pos())
                    if mouse_pos:
                        self.roi_start = mouse_pos
                        self.roi_selecting = True
                        self.roi_selected = False
                        logger.info(f"[ROI] Start selection at: {mouse_pos.x()}, {mouse_pos.y()}")
                    return True
                    
            # 4.7.3 è™•ç†æ»‘é¼ ç§»å‹•äº‹ä»¶ï¼Œå‹•æ…‹æ›´æ–° ROI å€åŸŸ
            elif event.type() == event.MouseMove:           # è™•ç†æ»‘é¼ ç§»å‹•äº‹ä»¶
                if self.roi_selecting and self.roi_start:
                    mouse_pos = self._convert_mouse_coords(event.pos())
                    if mouse_pos:
                        self.roi_end = mouse_pos
                        # é™ä½ ROI é è¦½æ›´æ–°é »ç‡ï¼Œé¿å…å¡é “
                        if self.frame_count % 3 == 0:  # æ¯3å¹€æ›´æ–°ä¸€æ¬¡
                            self._update_roi_preview()
                    return True
                    
            # 4.7.4 è™•ç†æ»‘é¼ å·¦éµé‡‹æ”¾äº‹ä»¶ï¼Œå®Œæˆ ROI é¸æ“‡
            elif event.type() == event.MouseButtonRelease:  # è™•ç†æ»‘é¼ é‡‹æ”¾äº‹ä»¶
                if event.button() == Qt.LeftButton and self.roi_selecting:
                    mouse_pos = self._convert_mouse_coords(event.pos())
                    if mouse_pos:
                        self.roi_end = mouse_pos
                        self.roi_selecting = False
                        self.roi_selected = True
                        self.roi_preview.show()
                        self._update_roi_preview()
                        logger.info(f"[ROI] Selection completed: ({self.roi_start.x()}, {self.roi_start.y()}) to ({self.roi_end.x()}, {self.roi_end.y()})")
                    return True
        
        # 4.7.5 å…¶ä»–äº‹ä»¶äº¤ç”±çˆ¶é¡åˆ¥è™•ç†
        return super().eventFilter(obj, event)
    
    
    # 4.8 æ»‘é¼ åæ¨™è½‰æ›
    def _convert_mouse_coords(self, mouse_pos):
        
        if self.current_frame is None:                                          # æ²’æœ‰ç•¶å‰å½±åƒå°±å›å‚³ None
            return None
            
        img_h, img_w = self.current_frame.shape[:2]                             # å–å¾—å½±åƒå°ºå¯¸
        
        return self.image_service.convert_mouse_to_image_coords(                # è½‰æ›åæ¨™
            mouse_pos, img_w, img_h,
            self.display_scale, self.display_offset_x, self.display_offset_y
        )
    
    
    # 4.9 æ›´æ–° ROI é è¦½è¦–çª— (ä¿®æ”¹ç‚ºä½¿ç”¨åŸå§‹ç•«é¢)
    def _update_roi_preview(self):
        
        if self.roi_start and self.roi_end and self.original_frame is not None:  # ä½¿ç”¨åŸå§‹ç•«é¢è€Œéç¸®æ”¾å¾Œçš„ç•«é¢
            roi_coords = self._get_roi_display_coords()                         # å–å¾— ROI åæ¨™
            if roi_coords:                                                      # ç¢ºä¿ ROI åæ¨™æœ‰æ•ˆ
                # å°‡é¡¯ç¤ºåæ¨™è½‰æ›ç‚ºåŸå§‹åœ–åƒåæ¨™
                orig_roi_coords = self._convert_display_to_original_coords(roi_coords)
                if orig_roi_coords:
                    # å¾åŸå§‹ç•«é¢æå– ROIï¼ˆæœªç¶“ resizeï¼‰
                    x1, y1, x2, y2 = orig_roi_coords
                    roi_frame = self.original_frame[y1:y2, x1:x2]
                    logger.info(f"[ROI] Extracted original ROI: {roi_frame.shape} from original: {self.original_frame.shape}")
                    self.roi_preview.update_preview(roi_frame)                      # æ›´æ–°é è¦½è¦–çª—
    
    def _convert_display_to_original_coords(self, roi_coords):
        """å°‡é¡¯ç¤ºåæ¨™è½‰æ›ç‚ºåŸå§‹åœ–åƒåæ¨™"""
        if self.original_frame is None:
            return None
        
        x1, y1, x2, y2 = roi_coords
        
        # ç²å–åŸå§‹åœ–åƒå’Œç•¶å‰é¡¯ç¤ºåœ–åƒçš„å°ºå¯¸
        orig_h, orig_w = self.original_frame.shape[:2]
        curr_h, curr_w = self.current_frame.shape[:2]
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
        scale_x = orig_w / curr_w
        scale_y = orig_h / curr_h
        
        # è½‰æ›åæ¨™åˆ°åŸå§‹åœ–åƒ
        orig_x1 = int(x1 * scale_x)
        orig_y1 = int(y1 * scale_y)
        orig_x2 = int(x2 * scale_x)
        orig_y2 = int(y2 * scale_y)
        
        # ç¢ºä¿åæ¨™åœ¨æœ‰æ•ˆç¯„åœå…§
        orig_x1 = max(0, min(orig_x1, orig_w - 1))
        orig_y1 = max(0, min(orig_y1, orig_h - 1))
        orig_x2 = max(0, min(orig_x2, orig_w - 1))
        orig_y2 = max(0, min(orig_y2, orig_h - 1))
        
        return (orig_x1, orig_y1, orig_x2, orig_y2)
    
    
    # 4.10 åˆ‡æ› ROI é¸æ“‡æ¨¡å¼
    def toggle_roi_mode(self):
        
        if self.roi_selected:                                                   # å¦‚æœå·²é¸æ“‡ ROIï¼Œå‰‡æ¸…é™¤        
            self.clear_roi()                                                    # æ¸…é™¤ ROI é¸æ“‡
        else:
            self.roi_btn.setText('é¸æ“‡è¾¨è­˜å€åŸŸ (æ‹–æ‹½æ¡†é¸ä¸­...)')                  # æ›´æ–°æŒ‰éˆ•æ–‡å­—
            logger.info("[ROI] ROI selection mode enabled")                     # è¨˜éŒ„æ—¥èªŒ
    
    
    # 4.11 æ¸…é™¤ ROI é¸æ“‡
    def clear_roi(self):
        
        self.roi_start = None                                                   # æ¸…é™¤èµ·é»
        self.roi_end = None                                                     # æ¸…é™¤çµ‚é»
        self.roi_selecting = False                                              # æ¸…é™¤é¸æ“‡ç‹€æ…‹
        self.roi_selected = False                                               # æ¸…é™¤å·²é¸æ“‡ç‹€æ…‹
        self.roi_btn.setText('é¸æ“‡è¾¨è­˜å€åŸŸ (æ‹–æ‹½æ¡†é¸)')                           # é‡ç½®æŒ‰éˆ•æ–‡å­—
        self.roi_preview.hide()                                                 # éš±è—é è¦½è¦–çª—
        self.roi_preview.clear_preview()                                        # æ¸…é™¤é è¦½å…§å®¹
        logger.info("[ROI] ROI selection cleared")                              # è¨˜éŒ„æ—¥èªŒ
    
    # ====================================================
    # ========== Step 4.12 æ‹ç…§ä¸¦é€²è¡Œ OCR è¾¨è­˜ =============
    # ====================================================
    
    # å‚™è¨»: 
    # é€™å€‹å‡½å¼è¢«å‘¼å«å¾Œå°‡æœƒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿ
    # 1. æ ¹æ“šæ˜¯å¦é¸æ“‡ ROIï¼Œæ±ºå®šä½¿ç”¨å…¨ç•«é¢æˆ– ROI å€åŸŸé€²è¡Œ OCR
    # 2. ä½¿ç”¨ ImageProcessingService é€²è¡Œå“è³ªå¢å¼·
    # 3. å‘¼å« Gemini OCR API é€²è¡Œè¾¨è­˜
    # 4. æ ¹æ“šè¾¨è­˜çµæœèˆ‡ç™½åå–®é€²è¡Œè¨±å¯/ç•°å¸¸åˆ¤æ–·
    # 5. é¡¯ç¤ºè¾¨è­˜çµæœèˆ‡åˆ¤æ–·ç‹€æ…‹
    
    def capture_and_ocr(self):
        
        # 4.12.0 ç¢ºä¿æœ‰ç•¶å‰å½±åƒ
        if self.current_frame is None:                                          # ç¢ºä¿æœ‰ç•¶å‰å½±åƒ
            logger.warning("[OCR] No frame available for capture")              # è¨˜éŒ„è­¦å‘Š
            return

        # 4.12.1 è¨±å¯äººå“¡ç™½åå–®ï¼Œå¯æ”¹ç‚ºè®€å–å¤–éƒ¨æª”æ¡ˆ
        whitelist = [
            {"id_number": "A123456789", "name": "ç‹å°æ˜"},
            {"id_number": "B987654321", "name": "æå°è¯"},
        ]

        # 4.12.2 å®šç¾©è¨±å¯åˆ¤æ–·å‡½å¼ï¼Œæ­¤å‡½å¼ç‚ºå…§éƒ¨å‡½å¼ï¼Œä¸æœƒè¢«å¤–éƒ¨å‘¼å«
        def is_permitted(ocr_result, whitelist):
            for person in whitelist:
                if (ocr_result.get("id_number") == person["id_number"] and      # æ¯”å°èº«åˆ†è­‰è™Ÿ
                    ocr_result.get("name") == person["name"]):                  # æ¯”å°å§“å
                    return True
            return False

        try:
            # 4.12.3 æ±ºå®šè™•ç†å€åŸŸ
            if self.roi_selected and self.roi_start and self.roi_end:           # ä½¿ç”¨ ROI å€åŸŸ
                roi_coords = self._get_roi_display_coords()                     # å–å¾— ROI åæ¨™
                # ä½¿ç”¨åŸå§‹ç•«é¢æå– ROIï¼Œç¢ºä¿ OCR ä¹Ÿä½¿ç”¨é«˜è§£æåº¦
                orig_roi_coords = self._convert_display_to_original_coords(roi_coords)
                if orig_roi_coords:
                    x1, y1, x2, y2 = orig_roi_coords
                    processed_frame = self.original_frame[y1:y2, x1:x2]         # å¾åŸå§‹ç•«é¢æå– ROI
                    logger.info(f"[OCR] Using original ROI region for OCR: {processed_frame.shape}")
                else:
                    logger.error("[OCR] Failed to convert ROI coordinates")
                    return
            else:
                processed_frame = self.original_frame if self.original_frame is not None else self.current_frame  # ä½¿ç”¨åŸå§‹å…¨ç•«é¢
                logger.info("[OCR] Using original full frame for OCR")           # è¨˜éŒ„æ—¥èªŒ

            if processed_frame is None:
                self.result_text.setText("éŒ¯èª¤ï¼šç„¡æ³•ç²å–æœ‰æ•ˆçš„å½±åƒå€åŸŸ")          # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                return

            # 4.12.4 å“è³ªå¢å¼·
            processed_frame = self.image_service.enhance_frame_quality(processed_frame)     # å‘¼å« image_service é€²è¡Œå“è³ªå¢å¼·

            # 4.12.5 å„²å­˜æš«å­˜åœ–ç‰‡
            img_path = 'temp_capture.jpg'
            cv2.imwrite(img_path, processed_frame)

            # 4.12.6 è®€å–åœ–ç‰‡ç‚ºä½å…ƒçµ„ä¸¦å‘¼å« Gemini OCR
            with open(img_path, 'rb') as f:
                image_bytes = f.read()

            logger.info(f"[OCR] Processing image with size: {processed_frame.shape}")
            img_part = {
                "mime_type": "image/jpeg",
                "data": image_bytes
            }

            resp = model.generate_content(                                                  # å‘¼å« Gemini OCR API
                [img_part, "é€™æ˜¯ä¸€å¼µå°ç£èº«ä»½è­‰ç…§ç‰‡ï¼Œè«‹å›å‚³èº«åˆ†è­‰è™Ÿ(id_number)èˆ‡å§“å(name)ã€‚"],  # æä¾›åœ–ç‰‡èˆ‡æç¤ºèª
                generation_config=genai.GenerationConfig(                                   # è¨­å®šå›æ‡‰æ ¼å¼
                    response_mime_type="application/json",                                  # å›å‚³ JSON æ ¼å¼
                    response_schema=TaiwanIDCard                                            # ä½¿ç”¨å®šç¾©çš„ Schema
                )
            )
            
            # å‚™è¨»:
            # Gemini OCR API æä¾›å¯è§£æçš„ JSON å›æ‡‰ï¼ŒåŒ…å«è¾¨è­˜å‡ºçš„èº«åˆ†è­‰è™Ÿèˆ‡å§“å
            # å›æ‡‰æ ¼å¼ç¯„ä¾‹: {"id_number": "A123456789", "name": "ç‹å°æ˜"}
            # è‹¥å›æ‡‰ç„¡æ³•è§£æï¼Œæœƒé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ä¸¦çµæŸ

            # 4.12.7 è™•ç†å›æ‡‰
            ocr_result = None
            result_text = ""
            if resp.candidates and resp.candidates[0].content and resp.candidates[0].content.parts: # æª¢æŸ¥å›æ‡‰çµæ§‹
                part = resp.candidates[0].content.parts[0]                                          # å–å¾—ç¬¬ä¸€å€‹éƒ¨åˆ†
                
                if part.function_call:                                                              # æª¢æŸ¥æ˜¯å¦ç‚ºå‡½å¼å‘¼å«å›æ‡‰
                    parsed_args = dict(part.function_call.args)                                     # è§£æå‡½å¼åƒæ•¸
                    ocr_result = parsed_args                                                        # å„²å­˜ OCR çµæœ
                    result_text = json.dumps(parsed_args, ensure_ascii=False, indent=2)             # æ ¼å¼åŒ–é¡¯ç¤ºçµæœ
                
                elif resp.text:                                                                     # æœ‰æ–‡å­—å›æ‡‰ä½†ç„¡æ³•è§£æç‚ºå‡½å¼å‘¼å«
                    try:
                        parsed_args = json.loads(resp.text)                                         # å˜—è©¦è§£æ JSON
                        ocr_result = parsed_args                                                    # å„²å­˜ OCR çµæœ
                        result_text = resp.text                                                     # é¡¯ç¤ºåŸå§‹æ–‡å­—å›æ‡‰
                    except json.JSONDecodeError:                                                    # è§£æå¤±æ•—
                        self.result_text.setText(f"ç„¡æ³•è§£æOCRå›æ‡‰ã€‚\n\nåŸå§‹å›æ‡‰:\n{resp.text}")
                        return
                else:
                    self.result_text.setText("ç„¡æ³•è§£æOCRå›æ‡‰ï¼Œä¸”æ²’æœ‰æ”¶åˆ°æ–‡å­—å›æ‡‰ã€‚")
                    return
            else:
                error_message = "ç„¡æ³•è§£æOCRå›æ‡‰ã€‚è«‹å†è©¦ä¸€æ¬¡ã€‚"
                if resp.text:
                    error_message += f"\n\nåŸå§‹å›æ‡‰:\n{resp.text}"
                self.result_text.setText(error_message)
                return

            # 4.12.8 è¨±å¯/ç•°å¸¸åˆ¤æ–·
            if ocr_result:
                permitted = is_permitted(ocr_result, whitelist)
                status_str = "âœ… è¨±å¯äººå“¡" if permitted else "âŒ ç•°å¸¸äººå“¡"
                result_text += f"\n---\nPythonç‰©ä»¶ï¼š\nèº«åˆ†è­‰è™Ÿ: {ocr_result.get('id_number', 'N/A')}\nå§“å: {ocr_result.get('name', 'N/A')}\nèº«ä»½åˆ¤æ–·ï¼š{status_str}"
                self.result_text.setText(result_text)
            else:
                self.result_text.setText("OCR çµæœç„¡æ³•åˆ¤æ–·è¨±å¯/ç•°å¸¸äººå“¡ã€‚")

        except Exception as e:
            logger.error(f"[OCR] Error during OCR processing: {e}")
            self.result_text.setText(f"OCR ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        finally:
            try:
                os.remove(img_path)
            except:
                pass
    
    
    # 4.13 é—œé–‰äº‹ä»¶è™•ç† (ä¿®æ”¹ç‚ºæ¸…ç† OBS è³‡æº)
    def closeEvent(self, event):
        """é—œé–‰äº‹ä»¶è™•ç†"""
        logger.info('[OCR] Shutting down...')
        self.timer.stop()
        self.cleanup_timer.stop()
        
        # æ¸…ç† OBS è³‡æº
        if self.obs_video_capture:
            self.obs_video_capture.stop()
            self.obs_video_capture = None
        
        if self.obs_audio_capture:
            self.obs_audio_capture.stop_capture()
            self.obs_audio_capture = None
        
        # æ¸…ç† Insta Worker
        if self.insta_worker:
            self.insta_worker.stop_all()
            self.insta_worker = None
        
        # æ¸…ç†ç³»çµ±ç›£æ§
        if hasattr(self, 'system_monitor'):
            self.system_monitor.stop_monitoring()
        
        # é—œé–‰ ROI é è¦½çª—å£
        if hasattr(self, 'roi_preview'):
            self.roi_preview.close()
        
        logger.info('[OCR] Shutdown complete.')
        event.accept()

# =============================================================
# ================= Step 5 è¼¸å‡ºç´€éŒ„æ•¸å€¼è®ŠåŒ– csv ==================
# =============================================================

# åœ¨æ­¤ç´€éŒ„ä¸‹ GPU ä½¿ç”¨ç‹€æ³ã€CPU ä½¿ç”¨ç‡ã€è¨˜æ†¶é«”å’Œç•«é¢ FPS è®ŠåŒ–ç­‰ç³»çµ±è³‡æºæ•¸å€¼è®ŠåŒ–
# å¯é¸æ“‡æ€§å°‡é€™äº›æ•¸å€¼è¼¸å‡ºåˆ° CSV æª”æ¡ˆä¸­ï¼Œæ–¹ä¾¿å¾ŒçºŒåˆ†æ
# ä¾‹å¦‚: åœ¨ get_global_system_monitor() ä¸­åŠ å…¥ CSV è¼¸å‡ºåŠŸèƒ½
# æˆ–åœ¨ OCRCameraWidget ä¸­å®šæœŸå°‡ self.system_monitor.get_resource_summary() å¯«å…¥ CSV
# é€™éƒ¨åˆ†å¯ä¾éœ€æ±‚è‡ªè¡Œæ“´å±•

def export_system_metrics_to_csv(system_monitor, csv_path='system_metrics.csv'):
    import csv
    import logging
    logger = logging.getLogger(__name__)
    
    while True:
        try:
            with open(csv_path, mode='a', newline='') as file:
                writer = csv.writer(file)
                # è‹¥æª”æ¡ˆå‰›å»ºç«‹ï¼Œå¯«å…¥æ¨™é¡Œ
                if file.tell() == 0:
                    writer.writerow(['Timestamp', 'CPU_Usage(%)', 'Memory_Usage(%)', 'Memory_Used(GB)', 'GPU_Usage(%)', 'GPU_Memory_Used(MB)', 'GPU_Temp(C)', 'CPU_Temp(C)', 'FPS', 'Frame_Count', 'Latency(ms)'])
                
                # ç›´æ¥ç²å– SystemMetrics å°è±¡
                metrics = system_monitor.get_metrics()
                timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
                
                # å˜—è©¦ç²å–FPSæ•¸æ“šï¼ˆå¾å…¨åŸŸæˆ–å…¶ä»–ä¾†æºï¼‰
                fps = 0.0
                frame_count = 0
                latency = 0.0
                try:
                    # å˜—è©¦å¾performance monitorç²å–FPSæ•¸æ“š
                    from Insta_OpenCV.services.performance_monitor import get_global_performance_monitor
                    perf_monitor = get_global_performance_monitor()
                    perf_metrics = perf_monitor.get_metrics()
                    fps = perf_metrics.fps
                    frame_count = perf_metrics.frame_count
                    latency = perf_metrics.latency
                except Exception as e:
                    logger.debug(f"[SystemMetrics] Could not get FPS data: {e}")
                
                writer.writerow([
                    timestamp,
                    round(metrics.cpu_percent, 2),
                    round(metrics.memory_percent, 2),
                    round(metrics.memory_used_gb, 2),
                    round(metrics.gpu_percent, 2),
                    round(metrics.gpu_memory_used_mb, 2),
                    round(metrics.gpu_temp, 2),
                    round(metrics.cpu_temp, 2),
                    round(fps, 2),
                    frame_count,
                    round(latency, 2)
                ])
                
                logger.debug(f"[SystemMetrics] Recorded: CPU={metrics.cpu_percent:.1f}%, GPU={metrics.gpu_percent:.1f}%, Memory={metrics.memory_percent:.1f}%, FPS={fps:.1f}")
                
        except Exception as e:
            # è¨˜éŒ„éŒ¯èª¤ä½†ä¸ä¸­æ–·åŸ·è¡Œç·’
            logger.warning(f"[SystemMetrics] Failed to write metrics: {e}")
        time.sleep(5)  # æ¯5ç§’ç´€éŒ„ä¸€æ¬¡


# ====================================================
# ================= Step 6 ä¸»ç¨‹å¼ ==================
# ====================================================

def main():
    
    app = QApplication(sys.argv)                                 # åˆå§‹åŒ– QApplication
    
    # åœ¨ QApplication å»ºç«‹å¾Œæª¢æŸ¥ä¸¦è¨­å®š API Key
    try:
        api_key = get_gemini_api_key()
        genai.configure(api_key=api_key)
        global model
        model = genai.GenerativeModel('gemini-1.5-pro')
    except Exception as e:
        QMessageBox.critical(None, "éŒ¯èª¤", f"API Key è¨­å®šå¤±æ•—: {e}")
        return
    
    try:
        window = OCRCameraWidget()                               # åˆå§‹åŒ–ä¸»è¦–çª—
        window.show()                                            # é¡¯ç¤ºä¸»è¦–çª—
        sys.exit(app.exec_())                                    # åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼ä¸»è¿´åœˆ
    except Exception as e:                                       # æ•æ‰æ‰€æœ‰ç•°å¸¸
        logger.error(f"[Main] Application error: {e}")           # è¨˜éŒ„éŒ¯èª¤
        sys.exit(1)                                              # éæ­£å¸¸é€€å‡º

if __name__ == '__main__':
    main()
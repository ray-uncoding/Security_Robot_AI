# ====================================================
# ========== Step 1 åŸºæœ¬åŒ¯å…¥èˆ‡åˆå§‹åŒ– =============
# ====================================================

# 1.1 æ¨™æº–åº«èˆ‡ç¬¬ä¸‰æ–¹å¥—ä»¶åŒ¯å…¥
import pyaudio
import speech_recognition as sr
import google.generativeai as genai
import json
import os
import time, math, threading

# 1.2 å…¨åŸŸè®Šæ•¸ï¼Œæ±ºå®šæ˜¯å¦çœŸçš„æ§åˆ¶æ©Ÿå™¨äºº
CONTROL_ROBOT = True   # True: ç™¼é€ /cmd_vel æ§åˆ¶è»Šå­ï¼›False: åªå°å‡ºæŒ‡ä»¤

if CONTROL_ROBOT:
    import rclpy
    from rclpy.node import Node
    from geometry_msgs.msg import Twist, PoseStamped
    from nav2_simple_commander.robot_navigator import BasicNavigator, TaskResult

# ====================================================
# ========== Step 2 æ©Ÿå™¨äººæ§åˆ¶ =============
# ====================================================

    # 2.1 æ©Ÿå™¨äººæ§åˆ¶é¡åˆ¥
    class RobotController(Node):
        
        # 2.2 åˆå§‹åŒ–
        def __init__(self):
            super().__init__('voice_command_controller')
            self.publisher_ = self.create_publisher(Twist, '/cmd_vel', 10)
            
            # åˆå§‹åŒ– Nav2 å°èˆª
            self.navigator = BasicNavigator()
            
            # è¼‰å…¥èˆªé»é…ç½®
            self.waypoints = self.load_waypoints()

            # ä½ åŸæœ¬çš„åŸºæº–é€Ÿåº¦ï¼ˆå¯ä¾éœ€æ±‚èª¿ï¼‰
            self.linear_speed  = 0.20   # m/s
            self.angular_speed = 0.50   # rad/s

            # å…§éƒ¨ç‹€æ…‹ï¼šè®“æ–°å‘½ä»¤å¯ä»¥ä¸­æ–·èˆŠçš„é€£çºŒç™¼é€
            self._stop_event = threading.Event()
            self._worker = None

        # 2.3 é€£çºŒç™¼é€ Twist çš„å…§éƒ¨å‡½å¼
        def _publish_twist_stream(self, lin_x: float, ang_z: float, hz: int, duration: float):
            """é€£çºŒåœ¨ hz é »ç‡ä¸‹ç™¼é€ Twistï¼ŒæŒçºŒ duration ç§’ï¼›æ”¯æ´ stop ä¸­æ–·ã€‚"""
            period = 1.0 / float(hz)
            t_end = time.monotonic() + max(0.0, duration)

            twist = Twist()
            while not self._stop_event.is_set() and time.monotonic() < t_end:                   # æŒçºŒç™¼é€ç›´åˆ°æ™‚é–“åˆ°æˆ–è¢«ä¸­æ–·
                twist.linear.x = lin_x;  twist.linear.y = 0.0; twist.linear.z = 0.0             # ç·šé€Ÿåº¦
                twist.angular.x = 0.0;   twist.angular.y = 0.0; twist.angular.z = ang_z         # è§’é€Ÿåº¦
                self.publisher_.publish(twist)                                                  # ç™¼é€
                time.sleep(period)

            # åœæ­¢ï¼šè£œç™¼ 0 è®“è»Šç¢ºå¯¦ç…ä½
            stop = Twist()
            self.publisher_.publish(stop)

        # 2.4 ä¸­æ–·ç›®å‰çš„é€£çºŒç™¼é€
        def stop_motion(self):
            """ä¸­æ–·ç›®å‰çš„é€£çºŒç™¼é€ï¼ˆç­‰åŒæ–¼æ”¾é–‹éµã€æˆ–èªéŸ³èªª stopï¼‰ã€‚"""
            self._stop_event.set()
            if self._worker and self._worker.is_alive():
                self._worker.join(timeout=1.0)
            self._worker = None
            self._stop_event.clear()

        # 2.5 ä¸»è¦çš„æŒ‡ä»¤è½‰æ›èˆ‡ç™¼é€å‡½å¼
        def send_command(self, action: str, value: float = 0.0, hold_sec: float | None = None, hz: int = 20):
            """
            å°‡æŠ½è±¡æŒ‡ä»¤è½‰ç‚ºé€£çºŒ /cmd_velï¼š
            - move_forward/backward: value ç•¶ã€Œè·é›¢ï¼ˆå…¬å°ºï¼‰ã€ï¼›è‹¥æ²’çµ¦ value å°±ç”¨ hold_sec æˆ–é è¨­ 2 ç§’
            - turn_left/right: value ç•¶ã€Œè§’åº¦ï¼ˆåº¦ï¼‰ã€ï¼›è‹¥æ²’çµ¦ value å°±ç”¨ hold_sec æˆ–é è¨­ 2 ç§’
            - stop: ç«‹åˆ»ä¸­æ–·ã€ä¸¦è£œç™¼ 0
            """
            # å…ˆä¸­æ­¢ä»»ä½•èˆŠçš„æµ
            self.stop_motion()

            # è½‰æˆ (lin_x, ang_z) èˆ‡ duration
            lin_x, ang_z = 0.0, 0.0
            duration = 2.0 if hold_sec is None else float(hold_sec)

            if action == "move_forward":
                lin_x = +self.linear_speed
                if value and value > 0:
                    duration = max(0.05, float(value) / abs(self.linear_speed))
            elif action == "move_backward":
                lin_x = -self.linear_speed
                if value and value > 0:
                    duration = max(0.05, float(value) / abs(self.linear_speed))
            elif action == "turn_left":
                ang_z = +self.angular_speed
                if value and value != 0:
                    rad = float(value) * math.pi / 180.0
                    duration = max(0.05, abs(rad) / abs(self.angular_speed))
            elif action == "turn_right":
                ang_z = -self.angular_speed
                if value and value != 0:
                    rad = float(value) * math.pi / 180.0
                    duration = max(0.05, abs(rad) / abs(self.angular_speed))
            elif action == "stop":
                # ç›´æ¥åœã€è£œç™¼é›¶
                self._publish_twist_stream(0.0, 0.0, hz=hz, duration=0.05)
                self.get_logger().info("âœ… åœæ­¢")
                return
            else:
                self.get_logger().warning(f"âŒ æœªçŸ¥æŒ‡ä»¤: {action}")
                return

            # é–‹æ–° thread é€£çºŒç™¼é€ï¼ˆç­‰åŒã€ŒæŒ‰ä½éµã€ï¼‰
            self._stop_event.clear()
            self._worker = threading.Thread(
                target=self._publish_twist_stream,
                args=(lin_x, ang_z, hz, duration),
                daemon=True
            )
            self._worker.start()
            self.get_logger().info(f"â–¶ï¸ é€£çºŒç™¼é€: action={action}, lin_x={lin_x:.3f}, ang_z={ang_z:.3f}, "
                                f"hz={hz}, duration={duration:.2f}s")

        # 2.6 è¼‰å…¥èˆªé»é…ç½®
        def load_waypoints(self):
            """è¼‰å…¥èˆªé»é…ç½®æª”æ¡ˆ"""
            try:
                with open('/home/nvidia/workspace/Security_Robot_AI/robot_projects/Sr_robot_Base/wheeltec_robot_nav2/map/saved_points.json', 'r') as file:
                    data = json.load(file)
                waypoints = data["points"]
                self.get_logger().info(f"âœ… æˆåŠŸè¼‰å…¥ {len(waypoints)} å€‹èˆªé»")
                return waypoints
            except Exception as e:
                self.get_logger().error(f"âŒ è¼‰å…¥èˆªé»å¤±æ•—: {e}")
                return []

        # 2.7 å°èˆªåˆ°æŒ‡å®šé»ä½
        def navigate_to_waypoint(self, point_number):
            """å°èˆªåˆ°æŒ‡å®šç·¨è™Ÿçš„é»ä½"""
            try:
                if not self.waypoints:
                    self.get_logger().error("âŒ æ²’æœ‰å¯ç”¨çš„èˆªé»")
                    return False
                    
                if point_number < 1 or point_number > len(self.waypoints):
                    self.get_logger().error(f"âŒ é»ä½ç·¨è™Ÿ {point_number} è¶…å‡ºç¯„åœ (1-{len(self.waypoints)})")
                    return False
                
                # ç­‰å¾… Nav2 å•Ÿå‹•
                self.navigator.waitUntilNav2Active()
                
                # é¸æ“‡ç›®æ¨™é»ä½ (å¾ 1 é–‹å§‹è¨ˆæ•¸ï¼Œæ‰€ä»¥è¦ -1)
                wp = self.waypoints[point_number - 1]
                
                goal_pose = PoseStamped()
                goal_pose.header.frame_id = 'map'
                goal_pose.header.stamp = self.navigator.get_clock().now().to_msg()
                goal_pose.pose.position.x = wp["x"]
                goal_pose.pose.position.y = wp["y"]
                goal_pose.pose.position.z = wp["z"]
                goal_pose.pose.orientation.x = wp["qx"]
                goal_pose.pose.orientation.y = wp["qy"]
                goal_pose.pose.orientation.z = wp["qz"]
                goal_pose.pose.orientation.w = wp["qw"]
                
                self.get_logger().info(f"ğŸ¯ é–‹å§‹å°èˆªåˆ°é»ä½ {point_number}: ({wp['x']:.2f}, {wp['y']:.2f})")
                
                # é–‹å§‹å°èˆª
                self.navigator.goToPose(goal_pose)
                
                return True
                
            except Exception as e:
                self.get_logger().error(f"âŒ å°èˆªå¤±æ•—: {e}")
                return False

# ====================================================
# ========== Step 3 Gemini API åˆå§‹åŒ– =============
# ====================================================

# 3.1 åˆå§‹åŒ– Gemini æ¨¡å‹
genai.configure(api_key=os.environ.get("GEMINI_API_KEY", "YOUR_API_KEY"))

# 3.2 Schema é©…å‹• JSON è¼¸å‡ºæ ¼å¼ - åŸºæœ¬ç§»å‹•
response_schema_basic = {
    "type": "object",
    "properties": {
        "action": {
            "type": "string",
            "enum": ["move_forward", "move_backward", "turn_left", "turn_right", "stop"]
        },
        "value": {"type": "number"}
    },
    "required": ["action"]
}

# 3.3 Schema é©…å‹• JSON è¼¸å‡ºæ ¼å¼ - å°èˆª
response_schema_navigation = {
    "type": "object",
    "properties": {
        "action": {
            "type": "string",
            "enum": ["go_to_location"]
        },
        "value": {"type": "number"}
    },
    "required": ["action"]
}

# 3.4 å»ºç«‹ Gemini æ¨¡å‹ç‰©ä»¶ - åŸºæœ¬ç§»å‹•
model_basic = genai.GenerativeModel(
    "gemini-2.5-pro",
    generation_config={
        "response_mime_type": "application/json",
        "response_schema": response_schema_basic
    }
)

# 3.5 å»ºç«‹ Gemini æ¨¡å‹ç‰©ä»¶ - å°èˆª
model_navigation = genai.GenerativeModel(
    "gemini-2.5-pro",
    generation_config={
        "response_mime_type": "application/json",
        "response_schema": response_schema_navigation
    }
)

# ====================================================
# ========== Step 4 Gemini API åˆå§‹åŒ– =============
# ====================================================

# 4.1 åˆå§‹åŒ– Gemini æ¨¡å‹
def choose_microphone():
    """åˆ—å‡ºéº¥å…‹é¢¨æ¸…å–®ä¸¦è®“ä½¿ç”¨è€…é¸æ“‡"""
    print("ğŸ¤ å¯ç”¨çš„éº¥å…‹é¢¨æ¸…å–®ï¼š")
    for i, mic_name in enumerate(sr.Microphone.list_microphone_names()):
        print(f"{i}: {mic_name}")
    mic_index = int(input("è«‹è¼¸å…¥è¦ä½¿ç”¨çš„éº¥å…‹é¢¨ index: "))
    print(f"âœ… å·²é¸æ“‡éº¥å…‹é¢¨ index {mic_index}")
    return mic_index

# 4.2 æ¸¬è©¦å‡½å¼
def test_microphone(mic_index):
    r = sr.Recognizer()
    with sr.Microphone(device_index=13, sample_rate=16000) as source:  # 12 æ˜¯ pulse

        print("ğŸ™ï¸ Step 1: è«‹è¬›è©±...")
        r.adjust_for_ambient_noise(source)
        try:
            audio = r.listen(source, timeout=5)
            print("ğŸ§ Step 2: éŒ„éŸ³å®Œæˆï¼Œè¾¨è­˜ä¸­...")
            text = r.recognize_google(audio, language="zh-TW")
            print("ğŸ§  è¾¨è­˜çµæœï¼š", text)
        except sr.WaitTimeoutError:
            print("âŒ ç­‰å¾…è¶…æ™‚ï¼Œæ²’åµæ¸¬åˆ°èªéŸ³ã€‚")
        except sr.UnknownValueError:
            print("ğŸ¤· ç„¡æ³•è¾¨è­˜èªéŸ³å…§å®¹")
        except sr.RequestError as e:
            print("ğŸŒ èªéŸ³æœå‹™éŒ¯èª¤ï¼š", e)

# 4.3 æ¸¬è©¦èªéŸ³è¾¨è­˜
def test_speech_recognition(mic_index):
    """æ¸¬è©¦ Google èªéŸ³è¾¨è­˜"""
    r = sr.Recognizer()
    with sr.Microphone(device_index=mic_index) as source:
        r.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ Step 2: è«‹è¬›è©±...")
        audio = r.listen(source)
    text = r.recognize_google(audio, language="zh-TW")
    print("âœ… è¾¨è­˜çµæœ:", text)
    return text

# 4.4 æ¸¬è©¦ Gemini JSON è¼¸å‡º - åŸºæœ¬ç§»å‹•
def test_gemini_json():
    """æ‰‹å‹•è¼¸å…¥æ–‡å­—ï¼Œæ¸¬è©¦ Gemini JSON è¼¸å‡º"""
    command = input("ğŸ¯ Step 3: è«‹è¼¸å…¥åŸºæœ¬ç§»å‹•æŒ‡ä»¤ (ä¾‹å¦‚ï¼šå‰é€² 5 å…¬å°º): ")
    response = model_basic.generate_content(f"å°‡ä»¥ä¸‹ä¸­æ–‡æŒ‡ä»¤è½‰æ›ç‚ºæ©Ÿå™¨äººåŸºæœ¬ç§»å‹•æŒ‡ä»¤ã€‚æ”¯æ´çš„å‹•ä½œï¼šmove_forward(å‰é€²), move_backward(å¾Œé€€), turn_left(å·¦è½‰), turn_right(å³è½‰), stop(åœæ­¢)ã€‚æŒ‡ä»¤ï¼š{command}")
    cmd = json.loads(response.text)
    print("âœ… Gemini è¼¸å‡º JSON:", cmd)
    return cmd

# 4.5 å®Œæ•´æµç¨‹æ¸¬è©¦ - åŸºæœ¬ç§»å‹•
def run_integration(mic_index, ros_controller=None):
    r = sr.Recognizer()
    with sr.Microphone(device_index=mic_index) as source:
        r.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ Step 4: è«‹è¬›å‡ºåŸºæœ¬ç§»å‹•æŒ‡ä»¤...")
        audio = r.listen(source)

    text = r.recognize_google(audio, language="zh-TW")
    print("ğŸ“ è¾¨è­˜æ–‡å­—:", text)

    try:
        response = model_basic.generate_content(f"å°‡ä»¥ä¸‹ä¸­æ–‡æŒ‡ä»¤è½‰æ›ç‚ºæ©Ÿå™¨äººåŸºæœ¬ç§»å‹•æŒ‡ä»¤ã€‚æ”¯æ´çš„å‹•ä½œï¼šmove_forward(å‰é€²), move_backward(å¾Œé€€), turn_left(å·¦è½‰), turn_right(å³è½‰), stop(åœæ­¢)ã€‚æŒ‡ä»¤ï¼š{text}")
        cmd = json.loads(response.text)
        print("ğŸ“¦ Gemini å¼·åˆ¶ JSON è¼¸å‡º:", cmd)
        execute_command_with_ros(cmd, ros_controller)   # <â”€â”€ å‚³é€²å»
    except Exception as e:
        print("âš ï¸ è§£æå¤±æ•—:", e)

# 4.6 èªéŸ³å°èˆªå¾ªç’°
def run_voice_navigation(mic_index, ros_controller=None):
    """æŒçºŒèªéŸ³å°èˆªæ¨¡å¼"""
    print("ğŸ¯ é€²å…¥èªéŸ³å°èˆªæ¨¡å¼ï¼Œèªªã€Œåœæ­¢ã€çµæŸç¨‹å¼")
    r = sr.Recognizer()
    
    while True:
        try:
            with sr.Microphone(device_index=mic_index) as source:
                r.adjust_for_ambient_noise(source)
                print("ğŸ™ï¸ è«‹èªªå‡ºå°èˆªæŒ‡ä»¤ (ä¾‹å¦‚ï¼šå»1è™Ÿé»ä½)...")
                audio = r.listen(source, timeout=10)

            text = r.recognize_google(audio, language="zh-TW")
            print("ğŸ“ è¾¨è­˜æ–‡å­—:", text)
            
            # æª¢æŸ¥æ˜¯å¦è¦é€€å‡º
            if "åœæ­¢" in text or "çµæŸ" in text or "é€€å‡º" in text:
                print("ğŸ‘‹ çµæŸèªéŸ³å°èˆª")
                break

            try:
                response = model_navigation.generate_content(f"å°‡ä»¥ä¸‹ä¸­æ–‡æŒ‡ä»¤è½‰æ›ç‚ºæ©Ÿå™¨äººå°èˆªæŒ‡ä»¤ã€‚æ”¯æ´çš„å‹•ä½œï¼šgo_to_location(å°èˆªåˆ°æŒ‡å®šé»ä½)ã€‚å¦‚æœç”¨æˆ¶èªªã€Œå»1è™Ÿé»ä½ã€æˆ–ã€Œå‰å¾€é»ä½2ã€ç­‰ï¼Œä½¿ç”¨go_to_locationå‹•ä½œï¼Œvalueè¨­ç‚ºé»ä½ç·¨è™Ÿã€‚æŒ‡ä»¤ï¼š{text}")
                cmd = json.loads(response.text)
                print("ğŸ“¦ Gemini è¼¸å‡º JSON:", cmd)
                execute_command_with_ros(cmd, ros_controller)
            except Exception as e:
                print("âš ï¸ è§£æå¤±æ•—:", e)
                
        except sr.WaitTimeoutError:
            print("â° ç­‰å¾…è¶…æ™‚ï¼Œç¹¼çºŒç›£è½...")
        except sr.UnknownValueError:
            print("ğŸ¤· ç„¡æ³•è¾¨è­˜èªéŸ³å…§å®¹")
        except sr.RequestError as e:
            print("ğŸŒ èªéŸ³æœå‹™éŒ¯èª¤ï¼š", e)
        except KeyboardInterrupt:
            print("ğŸ‘‹ ä½¿ç”¨è€…ä¸­æ–·ï¼ŒçµæŸç¨‹å¼")
            break

def get_default_mic_index():
    p = pyaudio.PyAudio()
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        if info["maxInputChannels"] > 0:
            print(f"ä½¿ç”¨éº¥å…‹é¢¨è£ç½®ï¼šIndex {i} - {info['name']}")
            return i
    raise RuntimeError("æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨çš„éº¥å…‹é¢¨è£ç½®")
# ====================================================
# ========== Step 4 ç™¼é€ ROS æŒ‡ä»¤ =============
# ====================================================

# 4.1 åˆå§‹åŒ– ROS2 èˆ‡ RobotController ä¸¦åŸ·è¡ŒæŒ‡ä»¤
def execute_command_with_ros(cmd, ros_controller=None):
    action = cmd.get("action")
    value = cmd.get("value", 0)

    if CONTROL_ROBOT and ros_controller is not None:
        if action == "go_to_location":
            ros_controller.navigate_to_waypoint(int(value))
        else:
            ros_controller.send_command(action, value)
    else:
        if action == "move_forward":
            print(f"ğŸš— è»Šå­å‰é€² {value} å…¬å°º")
        elif action == "move_backward":
            print(f"ğŸš— è»Šå­å¾Œé€€ {value} å…¬å°º")
        elif action == "turn_left":
            print(f"ğŸš— è»Šå­å·¦è½‰ {value} åº¦")
        elif action == "turn_right":
            print(f"ğŸš— è»Šå­å³è½‰ {value} åº¦")
        elif action == "stop":
            print("ğŸš— è»Šå­åœæ­¢")
        elif action == "go_to_location":
            print(f"ğŸ¯ å°èˆªåˆ°é»ä½ {int(value)}")
        else:
            print("âŒ æœªçŸ¥æŒ‡ä»¤:", action)


# ====================================================
# ========== Step 5 ä¸»ç¨‹å¼ =============
# ====================================================
if __name__ == "__main__":
    #mic_index = choose_microphone()   # äº’å‹•é¸æ“‡éº¥å…‹é¢¨
    #mic_index = get_default_mic_index()   # â† ä½¿ç”¨é è¨­éº¥å…‹é¢¨
    mic_index = 12   # â† æŒ‡å®šéº¥å…‹é¢¨ indexï¼ˆnvidia çš„ pulse audioï¼‰
    if CONTROL_ROBOT:
        rclpy.init()
        ros_controller = RobotController()
    else:
        ros_controller = None

    print("=== æ¸¬è©¦é¸å–® ===")
    print("1. æ¸¬è©¦éº¥å…‹é¢¨")
    print("2. æ¸¬è©¦èªéŸ³è¾¨è­˜")
    print("3. æ¸¬è©¦ Gemini JSON è¼¸å‡º (åŸºæœ¬ç§»å‹•)")
    print("4. åŸ·è¡ŒåŸºæœ¬ç§»å‹•æŒ‡ä»¤")
    print("5. èªéŸ³å°èˆªæ¨¡å¼")
    choice = input("è«‹è¼¸å…¥é¸é … (1-5): ")

    if choice == "1":
        test_microphone(mic_index)
    elif choice == "2":
        test_speech_recognition(mic_index)
    elif choice == "3":
        test_gemini_json()
    elif choice == "4":
        run_integration(mic_index, ros_controller)
    elif choice == "5":
        run_voice_navigation(mic_index, ros_controller)
    else:
        print("âŒ ç„¡æ•ˆé¸é …")
        
    if CONTROL_ROBOT:
        try:
            rclpy.spin(ros_controller)   # ä¿æŒ ROS2 node æ´»è‘—
        except KeyboardInterrupt:
            pass
        finally:
            ros_controller.destroy_node()
            rclpy.shutdown()

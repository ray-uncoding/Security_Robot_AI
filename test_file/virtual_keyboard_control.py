# ====================================================
# ========== Step 1 åŸºæœ¬åŒ¯å…¥èˆ‡åˆå§‹åŒ– =============
# ====================================================

# 1.1 æ¨™æº–åº«èˆ‡ç¬¬ä¸‰æ–¹å¥—ä»¶åŒ¯å…¥
import speech_recognition as sr
import google.generativeai as genai
import json
import os
import time, math, threading

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist

# 1.2 å…¨åŸŸè®Šæ•¸ï¼Œæ±ºå®šæ˜¯å¦çœŸçš„æ§åˆ¶æ©Ÿå™¨äºº
CONTROL_ROBOT = True   # True: ç™¼é€ /cmd_vel æ§åˆ¶è»Šå­ï¼›False: åªå°å‡ºæŒ‡ä»¤

# ====================================================
# ========== Step 2 æ©Ÿå™¨äººæ§åˆ¶ =============
# ====================================================

# 2.1 æ©Ÿå™¨äººæ§åˆ¶é¡åˆ¥
class RobotController(Node):
    
    # 2.2 åˆå§‹åŒ–
    def __init__(self):
        super().__init__('voice_command_controller')
        self.publisher_ = self.create_publisher(Twist, '/cmd_vel', 10)

        # ä½ åŸæœ¬çš„åŸºæº–é€Ÿåº¦ï¼ˆå¯ä¾éœ€æ±‚èª¿ï¼‰
        self.linear_speed  = 0.20   # m/s
        self.angular_speed = 0.50   # rad/s

        # å…§éƒ¨ç‹€æ…‹ï¼šè®“æ–°å‘½ä»¤å¯ä»¥ä¸­æ–·èˆŠçš„é€£çºŒç™¼é€
        self._stop_event = threading.Event()
        self._worker = None

    # 2.3 é€£çºŒç™¼é€ Twist çš„å…§éƒ¨å‡½å¼
    def _publish_twist_stream(self, lin_x: float, ang_z: float, hz: int, duration: float):
        """é€£çºŒåœ¨ hz é »ç‡ä¸‹ç™¼é€ Twistï¼ŒæŒçºŒ duration ç§’ï¼›æ”¯æ´ stop ä¸­æ–·ã€‚"""
        period = 1.0 / float(hz)
        t_end = time.monotonic() + max(0.0, duration)

        twist = Twist()
        while not self._stop_event.is_set() and time.monotonic() < t_end:                   # æŒçºŒç™¼é€ç›´åˆ°æ™‚é–“åˆ°æˆ–è¢«ä¸­æ–·
            twist.linear.x = lin_x;  twist.linear.y = 0.0; twist.linear.z = 0.0             # ç·šé€Ÿåº¦
            twist.angular.x = 0.0;   twist.angular.y = 0.0; twist.angular.z = ang_z         # è§’é€Ÿåº¦
            self.publisher_.publish(twist)                                                  # ç™¼é€
            time.sleep(period)

        # åœæ­¢ï¼šè£œç™¼ 0 è®“è»Šç¢ºå¯¦ç…ä½
        stop = Twist()
        self.publisher_.publish(stop)

    # 2.4 ä¸­æ–·ç›®å‰çš„é€£çºŒç™¼é€
    def stop_motion(self):
        """ä¸­æ–·ç›®å‰çš„é€£çºŒç™¼é€ï¼ˆç­‰åŒæ–¼æ”¾é–‹éµã€æˆ–èªéŸ³èªª stopï¼‰ã€‚"""
        self._stop_event.set()
        if self._worker and self._worker.is_alive():
            self._worker.join(timeout=1.0)
        self._worker = None
        self._stop_event.clear()

    # 2.5 ä¸»è¦çš„æŒ‡ä»¤è½‰æ›èˆ‡ç™¼é€å‡½å¼
    def send_command(self, action: str, value: float = 0.0, hold_sec: float | None = None, hz: int = 20):
        """
        å°‡æŠ½è±¡æŒ‡ä»¤è½‰ç‚ºé€£çºŒ /cmd_velï¼š
        - move_forward/backward: value ç•¶ã€Œè·é›¢ï¼ˆå…¬å°ºï¼‰ã€ï¼›è‹¥æ²’çµ¦ value å°±ç”¨ hold_sec æˆ–é è¨­ 2 ç§’
        - turn_left/right: value ç•¶ã€Œè§’åº¦ï¼ˆåº¦ï¼‰ã€ï¼›è‹¥æ²’çµ¦ value å°±ç”¨ hold_sec æˆ–é è¨­ 2 ç§’
        - stop: ç«‹åˆ»ä¸­æ–·ã€ä¸¦è£œç™¼ 0
        """
        # å…ˆä¸­æ­¢ä»»ä½•èˆŠçš„æµ
        self.stop_motion()

        # è½‰æˆ (lin_x, ang_z) èˆ‡ duration
        lin_x, ang_z = 0.0, 0.0
        duration = 2.0 if hold_sec is None else float(hold_sec)

        if action == "move_forward":
            lin_x = +self.linear_speed
            if value and value > 0:
                duration = max(0.05, float(value) / abs(self.linear_speed))
        elif action == "move_backward":
            lin_x = -self.linear_speed
            if value and value > 0:
                duration = max(0.05, float(value) / abs(self.linear_speed))
        elif action == "turn_left":
            ang_z = +self.angular_speed
            if value and value != 0:
                rad = float(value) * math.pi / 180.0
                duration = max(0.05, abs(rad) / abs(self.angular_speed))
        elif action == "turn_right":
            ang_z = -self.angular_speed
            if value and value != 0:
                rad = float(value) * math.pi / 180.0
                duration = max(0.05, abs(rad) / abs(self.angular_speed))
        elif action == "stop":
            # ç›´æ¥åœã€è£œç™¼é›¶
            self._publish_twist_stream(0.0, 0.0, hz=hz, duration=0.05)
            self.get_logger().info("âœ… åœæ­¢")
            return
        else:
            self.get_logger().warning(f"âŒ æœªçŸ¥æŒ‡ä»¤: {action}")
            return

        # é–‹æ–° thread é€£çºŒç™¼é€ï¼ˆç­‰åŒã€ŒæŒ‰ä½éµã€ï¼‰
        self._stop_event.clear()
        self._worker = threading.Thread(
            target=self._publish_twist_stream,
            args=(lin_x, ang_z, hz, duration),
            daemon=True
        )
        self._worker.start()
        self.get_logger().info(f"â–¶ï¸ é€£çºŒç™¼é€: action={action}, lin_x={lin_x:.3f}, ang_z={ang_z:.3f}, "
                               f"hz={hz}, duration={duration:.2f}s")

# ====================================================
# ========== Step 3 Gemini API åˆå§‹åŒ– =============
# ====================================================

# 3.1 åˆå§‹åŒ– Gemini æ¨¡å‹
genai.configure(api_key=os.environ.get("GEMINI_API_KEY", "YOUR_API_KEY"))

# 3.2 Schema é©…å‹• JSON è¼¸å‡ºæ ¼å¼
response_schema = {
    "type": "object",
    "properties": {
        "action": {
            "type": "string",
            "enum": ["move_forward", "move_backward", "turn_left", "turn_right", "stop"]
        },
        "value": {"type": "number"}
    },
    "required": ["action"]
}

# 3.3 å»ºç«‹ Gemini æ¨¡å‹ç‰©ä»¶
model = genai.GenerativeModel(
    "gemini-1.5-pro",
    generation_config={
        "response_mime_type": "application/json",
        "response_schema": response_schema
    }
)

# ====================================================
# ========== Step 4 Gemini API åˆå§‹åŒ– =============
# ====================================================

# 4.1 åˆå§‹åŒ– Gemini æ¨¡å‹
def choose_microphone():
    """åˆ—å‡ºéº¥å…‹é¢¨æ¸…å–®ä¸¦è®“ä½¿ç”¨è€…é¸æ“‡"""
    print("ğŸ¤ å¯ç”¨çš„éº¥å…‹é¢¨æ¸…å–®ï¼š")
    for i, mic_name in enumerate(sr.Microphone.list_microphone_names()):
        print(f"{i}: {mic_name}")
    mic_index = int(input("è«‹è¼¸å…¥è¦ä½¿ç”¨çš„éº¥å…‹é¢¨ index: "))
    print(f"âœ… å·²é¸æ“‡éº¥å…‹é¢¨ index {mic_index}")
    return mic_index

# 4.2 æ¸¬è©¦å‡½å¼
def test_microphone(mic_index):
    """æ¸¬è©¦ PyAudio èƒ½å¦æ­£å¸¸éŒ„éŸ³"""
    r = sr.Recognizer()
    with sr.Microphone(device_index=mic_index) as source:
        r.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ Step 1: è«‹è¬›è©±...")
        audio = r.listen(source)
    print("âœ… éº¥å…‹é¢¨ OKï¼ŒéŒ„åˆ°éŸ³è¨Šé•·åº¦:", len(audio.frame_data))

# 4.3 æ¸¬è©¦èªéŸ³è¾¨è­˜
def test_speech_recognition(mic_index):
    """æ¸¬è©¦ Google èªéŸ³è¾¨è­˜"""
    r = sr.Recognizer()
    with sr.Microphone(device_index=mic_index) as source:
        r.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ Step 2: è«‹è¬›è©±...")
        audio = r.listen(source)
    text = r.recognize_google(audio, language="zh-TW")
    print("âœ… è¾¨è­˜çµæœ:", text)
    return text

# 4.4 æ¸¬è©¦ Gemini JSON è¼¸å‡º
def test_gemini_json():
    """æ‰‹å‹•è¼¸å…¥æ–‡å­—ï¼Œæ¸¬è©¦ Gemini JSON è¼¸å‡º"""
    command = input("ğŸ¯ Step 3: è«‹è¼¸å…¥æŒ‡ä»¤ (ä¾‹å¦‚ï¼šå‰é€² 5 å…¬å°º): ")
    response = model.generate_content(command)
    cmd = json.loads(response.text)
    print("âœ… Gemini è¼¸å‡º JSON:", cmd)
    return cmd

# 4.5 å®Œæ•´æµç¨‹æ¸¬è©¦
def run_integration(mic_index, ros_controller=None):
    r = sr.Recognizer()
    with sr.Microphone(device_index=mic_index) as source:
        r.adjust_for_ambient_noise(source)
        print("ğŸ™ï¸ Step 4: è«‹è¬›å‡ºæŒ‡ä»¤...")
        audio = r.listen(source)

    text = r.recognize_google(audio, language="zh-TW")
    print("ğŸ“ è¾¨è­˜æ–‡å­—:", text)

    try:
        response = model.generate_content(text)
        cmd = json.loads(response.text)
        print("ğŸ“¦ Gemini å¼·åˆ¶ JSON è¼¸å‡º:", cmd)
        execute_command_with_ros(cmd, ros_controller)   # <â”€â”€ å‚³é€²å»
    except Exception as e:
        print("âš ï¸ è§£æå¤±æ•—:", e)


# ====================================================
# ========== Step 4 ç™¼é€ ROS æŒ‡ä»¤ =============
# ====================================================

# 4.1 åˆå§‹åŒ– ROS2 èˆ‡ RobotController ä¸¦åŸ·è¡ŒæŒ‡ä»¤
def execute_command_with_ros(cmd, ros_controller=None):
    action = cmd.get("action")
    value = cmd.get("value", 0)

    if CONTROL_ROBOT and ros_controller is not None:
        ros_controller.send_command(action, value)
    else:
        if action == "move_forward":
            print(f"ğŸš— è»Šå­å‰é€² {value} å…¬å°º")
        elif action == "move_backward":
            print(f"ğŸš— è»Šå­å¾Œé€€ {value} å…¬å°º")
        elif action == "turn_left":
            print(f"ğŸš— è»Šå­å·¦è½‰ {value} åº¦")
        elif action == "turn_right":
            print(f"ğŸš— è»Šå­å³è½‰ {value} åº¦")
        elif action == "stop":
            print("ğŸš— è»Šå­åœæ­¢")
        else:
            print("âŒ æœªçŸ¥æŒ‡ä»¤:", action)


# ====================================================
# ========== Step 5 ä¸»ç¨‹å¼ =============
# ====================================================
if __name__ == "__main__":
    #mic_index = choose_microphone()   # äº’å‹•é¸æ“‡éº¥å…‹é¢¨
    mic_index = 9   # â† ç›´æ¥æŒ‡å®š index

    if CONTROL_ROBOT:
        rclpy.init()
        ros_controller = RobotController()
    else:
        ros_controller = None

    print("=== æ¸¬è©¦é¸å–® ===")
    print("1. æ¸¬è©¦éº¥å…‹é¢¨")
    print("2. æ¸¬è©¦èªéŸ³è¾¨è­˜")
    print("3. æ¸¬è©¦ Gemini JSON è¼¸å‡º")
    print("4. åŸ·è¡Œæ•´åˆç‰ˆ")
    choice = input("è«‹è¼¸å…¥é¸é … (1-4): ")

    if choice == "1":
        test_microphone(mic_index)
    elif choice == "2":
        test_speech_recognition(mic_index)
    elif choice == "3":
        test_gemini_json()
    elif choice == "4":
        run_integration(mic_index, ros_controller)
    else:
        print("âŒ ç„¡æ•ˆé¸é …")
        
    if CONTROL_ROBOT:
        try:
            rclpy.spin(ros_controller)   # ä¿æŒ ROS2 node æ´»è‘—
        except KeyboardInterrupt:
            pass
        finally:
            ros_controller.destroy_node()
            rclpy.shutdown()
